// src/components/VideoCall.jsx
// è¦–è¨Šé€šè©±å…ƒä»¶ï¼ˆå«å³æ™‚èªéŸ³ç¿»è­¯ï¼‰

import { useState, useEffect, useRef, useCallback } from 'react';
import AgoraRTC from 'agora-rtc-sdk-ng';
import { io } from 'socket.io-client';
import { useAuth } from '../hooks/useAuth';
import api from '../services/api';
import './VideoCall.css';

// è¨­å®š Agora SDK æ—¥èªŒç­‰ç´š
AgoraRTC.setLogLevel(1); // 0: DEBUG, 1: INFO, 2: WARNING, 3: ERROR, 4: NONE

const WS_URL = import.meta.env.VITE_API_URL?.replace('http', 'ws') || 'ws://localhost:3000';
const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:3000';

export default function VideoCall({ matchId, partnerName, onClose }) {
  const { user } = useAuth();

  // ä½¿ç”¨ ref ä¾†ä¿å­˜ tracksï¼Œç¢ºä¿ cleanup æ™‚å¯ä»¥æ­£ç¢ºå­˜å–
  const clientRef = useRef(null);
  const localAudioTrackRef = useRef(null);
  const localVideoTrackRef = useRef(null);

  const [localVideoTrack, setLocalVideoTrack] = useState(null);
  const [localAudioTrack, setLocalAudioTrack] = useState(null);
  const [remoteVideoTrack, setRemoteVideoTrack] = useState(null);
  const [remoteAudioTrack, setRemoteAudioTrack] = useState(null);
  const [isConnected, setIsConnected] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isVideoOff, setIsVideoOff] = useState(false);
  const [error, setError] = useState(null);
  const [status, setStatus] = useState('');
  const [isReady, setIsReady] = useState(false);

  // èªéŸ³ç¿»è­¯ç‹€æ…‹
  const [isTranslating, setIsTranslating] = useState(false);
  const [mySubtitle, setMySubtitle] = useState('');
  const [partnerSubtitle, setPartnerSubtitle] = useState('');
  const [latency, setLatency] = useState(0);

  // Debug: ç›£è½å­—å¹• state è®ŠåŒ–
  useEffect(() => {
    console.log('[DEBUG] mySubtitle è®ŠåŒ–:', mySubtitle);
  }, [mySubtitle]);

  useEffect(() => {
    console.log('[DEBUG] partnerSubtitle è®ŠåŒ–:', partnerSubtitle);
  }, [partnerSubtitle]);

  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const startCallRef = useRef(null);

  // èªéŸ³ç¿»è­¯ refs
  const voiceWsRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioContextRef = useRef(null);
  const socketRef = useRef(null);  // Socket.IO for receiving translations

  // åˆå§‹åŒ– Agora client
  useEffect(() => {
    // å‰µå»ºæ–°çš„ client
    console.log('[VideoCall] Creating new Agora client');
    clientRef.current = AgoraRTC.createClient({ mode: 'rtc', codec: 'vp8' });
    const client = clientRef.current;

    // ç›£è½é ç«¯ç”¨æˆ¶ç™¼å¸ƒ
    client.on('user-published', async (user, mediaType) => {
      console.log('[VideoCall] Remote user published:', user.uid, mediaType);
      setStatus(`å°æ–¹å·²åŠ å…¥ (${mediaType})`);

      await client.subscribe(user, mediaType);

      if (mediaType === 'video') {
        setRemoteVideoTrack(user.videoTrack);
        setTimeout(() => {
          if (remoteVideoRef.current && user.videoTrack) {
            user.videoTrack.play(remoteVideoRef.current);
          }
        }, 100);
      }

      if (mediaType === 'audio') {
        setRemoteAudioTrack(user.audioTrack);
        user.audioTrack.play();
      }
    });

    // ç›£è½é ç«¯ç”¨æˆ¶å–æ¶ˆç™¼å¸ƒ
    client.on('user-unpublished', (user, mediaType) => {
      console.log('[VideoCall] Remote user unpublished:', user.uid, mediaType);
      if (mediaType === 'video') {
        setRemoteVideoTrack(null);
      }
      if (mediaType === 'audio') {
        setRemoteAudioTrack(null);
      }
    });

    // ç›£è½é ç«¯ç”¨æˆ¶é›¢é–‹
    client.on('user-left', (user) => {
      console.log('[VideoCall] Remote user left:', user.uid);
      setRemoteVideoTrack(null);
      setRemoteAudioTrack(null);
      setStatus('å°æ–¹å·²é›¢é–‹');
    });

    // ç›£è¯é€£ç·šç‹€æ…‹
    client.on('connection-state-change', (curState, prevState) => {
      console.log('[VideoCall] Connection state:', prevState, '->', curState);
      if (curState === 'DISCONNECTED') {
        setIsConnected(false);
        setStatus('å·²æ–·ç·š');
      }
    });

    setIsReady(true);
    console.log('[VideoCall] Client initialized and ready');

    // è‡ªå‹•é–‹å§‹é€šè©±
    startCallRef.current?.();

    return () => {
      // æ¸…ç†
      console.log('[VideoCall] Cleaning up client listeners');
      client.removeAllListeners();
    };
  }, []);

  // é–‹å§‹é€šè©±
  const startCall = async (withVideo = true) => {
    if (isConnecting || isConnected) return;

    const client = clientRef.current;
    if (!client) {
      setError('ç³»çµ±åˆå§‹åŒ–ä¸­ï¼Œè«‹ç¨å¾Œå†è©¦');
      return;
    }

    setIsConnecting(true);
    setError(null);
    setStatus('æ­£åœ¨é€£æ¥...');

    // åœ¨ try å¤–éƒ¨å®šç¾©ï¼Œè®“ catch å¯ä»¥å­˜å–
    let audioTrack = null;
    let videoTrack = null;

    try {
      // æª¢æŸ¥é€£ç·šç‹€æ…‹ï¼Œå¦‚æœå·²é€£ç·šå‰‡å…ˆé›¢é–‹
      console.log('[VideoCall] Current connection state:', client.connectionState);
      if (client.connectionState !== 'DISCONNECTED') {
        console.log('[VideoCall] Leaving previous channel...');
        await client.leave();
        // ç­‰å¾…ä¸€ä¸‹ç¢ºä¿ç‹€æ…‹æ›´æ–°
        await new Promise(resolve => setTimeout(resolve, 500));
      }

      // 1. å–å¾— Agora Token
      setStatus('å–å¾—æˆæ¬Š...');
      const response = await api.post('/api/agora/token', {
        channelName: matchId
      });
      const { token, appId, uid: tokenUid } = response.data;
      console.log('[VideoCall] Got token for channel:', matchId, 'appId:', appId);

      // 2. åŠ å…¥é »é“ (ä½¿ç”¨ token ä¸­çš„ uidï¼Œå¦‚æœæ˜¯ 0 å‰‡è®“ SDK è‡ªå‹•åˆ†é…)
      setStatus('åŠ å…¥é »é“...');
      const joinUid = tokenUid === 0 ? null : tokenUid;
      console.log('[VideoCall] Joining channel:', matchId, 'with uid:', joinUid);

      let actualUid;
      try {
        console.log('[VideoCall] Calling client.join...');
        actualUid = await client.join(appId, matchId, token, joinUid);
        console.log('[VideoCall] client.join() returned, uid:', actualUid);
        console.log('[VideoCall] Connection state immediately after join:', client.connectionState);
      } catch (joinError) {
        console.error('[VideoCall] Join failed with error:', joinError);
        console.error('[VideoCall] Error name:', joinError.name);
        console.error('[VideoCall] Error code:', joinError.code);
        throw new Error(`åŠ å…¥é »é“å¤±æ•—: ${joinError.message || joinError.code || 'Unknown error'}`);
      }

      // ç­‰å¾…é€£ç·šç‹€æ…‹è®Šæˆ CONNECTED
      let waitCount = 0;
      while (client.connectionState !== 'CONNECTED' && waitCount < 10) {
        console.log('[VideoCall] Waiting for CONNECTED state, current:', client.connectionState);
        await new Promise(resolve => setTimeout(resolve, 200));
        waitCount++;
      }

      if (client.connectionState !== 'CONNECTED') {
        console.error('[VideoCall] Failed to reach CONNECTED state, current:', client.connectionState);
        throw new Error('ç„¡æ³•é€£æ¥åˆ°é »é“ï¼Œè«‹é‡è©¦');
      }

      console.log('[VideoCall] Connection state confirmed CONNECTED');

      // 3. å»ºç«‹æœ¬åœ°è»Œé“
      setStatus('å–å¾—éº¥å…‹é¢¨å’Œç›¸æ©Ÿ...');

      // å˜—è©¦å–å¾—éº¥å…‹é¢¨
      try {
        // æ‰‹æ©Ÿç€è¦½å™¨å¯èƒ½éœ€è¦ä¸åŒçš„éŸ³è¨Šé…ç½®
        const audioConfigs = [
          { AEC: true, ANS: true, AGC: true }, // å•Ÿç”¨å›éŸ³æ¶ˆé™¤ã€é™å™ªã€è‡ªå‹•å¢ç›Š
          {}, // é è¨­é…ç½®
        ];

        let audioError = null;
        for (let i = 0; i < audioConfigs.length; i++) {
          try {
            console.log(`[VideoCall] Trying audio config ${i + 1}:`, audioConfigs[i]);
            audioTrack = await AgoraRTC.createMicrophoneAudioTrack(audioConfigs[i]);
            console.log('[VideoCall] Audio config succeeded:', i + 1);
            break;
          } catch (configErr) {
            console.warn(`[VideoCall] Audio config ${i + 1} failed:`, configErr.message);
            audioError = configErr;
            audioTrack = null;
          }
        }

        if (audioTrack) {
          localAudioTrackRef.current = audioTrack;
          setLocalAudioTrack(audioTrack);
          console.log('[VideoCall] Got audio track');
        } else {
          console.warn('[VideoCall] ç„¡æ³•å–å¾—éº¥å…‹é¢¨:', audioError?.message);
        }
      } catch (audioErr) {
        console.warn('[VideoCall] ç„¡æ³•å–å¾—éº¥å…‹é¢¨:', audioErr.message);
      }

      // å˜—è©¦å–å¾—ç›¸æ©Ÿ
      if (withVideo) {
        try {
          // æ‰‹æ©Ÿç€è¦½å™¨éœ€è¦æŒ‡å®š facingMode å’Œè¼ƒä½çš„è§£æåº¦
          const isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
          console.log('[VideoCall] Device type:', isMobile ? 'Mobile' : 'Desktop');

          // å˜—è©¦ä¸åŒçš„ç›¸æ©Ÿé…ç½®
          const cameraConfigs = [
            // é…ç½® 1: æ‰‹æ©Ÿå‰ç½®é¡é ­ï¼Œä½è§£æåº¦
            {
              facingMode: 'user',
              encoderConfig: isMobile ? '480p_1' : '720p_1',
            },
            // é…ç½® 2: ä¸æŒ‡å®š facingMode
            {
              encoderConfig: isMobile ? '480p_1' : '720p_1',
            },
            // é…ç½® 3: æœ€åŸºæœ¬é…ç½®
            {},
          ];

          let cameraError = null;
          for (let i = 0; i < cameraConfigs.length; i++) {
            try {
              console.log(`[VideoCall] Trying camera config ${i + 1}:`, cameraConfigs[i]);
              videoTrack = await AgoraRTC.createCameraVideoTrack(cameraConfigs[i]);
              console.log('[VideoCall] Camera config succeeded:', i + 1);
              break; // æˆåŠŸå°±è·³å‡º
            } catch (configErr) {
              console.warn(`[VideoCall] Camera config ${i + 1} failed:`, configErr.message);
              cameraError = configErr;
              videoTrack = null;
            }
          }

          if (!videoTrack) {
            throw cameraError || new Error('All camera configs failed');
          }

          localVideoTrackRef.current = videoTrack;
          setLocalVideoTrack(videoTrack);
          console.log('[VideoCall] Got video track');

          // é¡¯ç¤ºæœ¬åœ°è¦–è¨Š
          if (localVideoRef.current) {
            videoTrack.play(localVideoRef.current);
          }
        } catch (videoErr) {
          console.warn('[VideoCall] ç„¡æ³•å–å¾—ç›¸æ©Ÿ:', videoErr.message, videoErr);
          setError(`ç›¸æ©Ÿç„¡æ³•ä½¿ç”¨ï¼š${videoErr.message || 'æœªçŸ¥éŒ¯èª¤'}ï¼Œåƒ…èªéŸ³æ¨¡å¼`);
        }
      }

      // 4. ç™¼å¸ƒè»Œé“
      setStatus('ç™¼å¸ƒåª’é«”...');
      const tracksToPublish = [audioTrack, videoTrack].filter(Boolean);

      // ç¢ºèªå·²æˆåŠŸåŠ å…¥é »é“
      if (client.connectionState !== 'CONNECTED') {
        throw new Error('åŠ å…¥é »é“å¤±æ•—ï¼Œè«‹é‡è©¦');
      }

      if (tracksToPublish.length > 0) {
        console.log('[VideoCall] Publishing tracks...');
        await client.publish(tracksToPublish);
        console.log('[VideoCall] Published tracks:', tracksToPublish.length);
      } else {
        console.warn('[VideoCall] No tracks to publish');
      }

      setIsConnected(true);
      setStatus('å·²é€£æ¥ï¼Œç­‰å¾…å°æ–¹åŠ å…¥...');
      console.log('[VideoCall] Connected to channel:', matchId);

    } catch (err) {
      console.error('[VideoCall] Failed to start call:', err);
      setError(err.message || 'ç„¡æ³•é–‹å§‹é€šè©±');
      setStatus('é€£æ¥å¤±æ•—');

      // æ¸…ç† - ä½¿ç”¨å±€éƒ¨è®Šæ•¸è€Œé state
      if (audioTrack) {
        audioTrack.stop();
        audioTrack.close();
      }
      if (videoTrack) {
        videoTrack.stop();
        videoTrack.close();
      }
      localAudioTrackRef.current = null;
      localVideoTrackRef.current = null;
      setLocalAudioTrack(null);
      setLocalVideoTrack(null);

      try {
        if (client.connectionState !== 'DISCONNECTED') {
          await client.leave();
        }
      } catch (e) {
        console.warn('[VideoCall] Error leaving channel:', e);
      }
    } finally {
      setIsConnecting(false);
    }
  };

  // å„²å­˜ startCall åˆ° refï¼Œè®“ useEffect å¯ä»¥å‘¼å«
  startCallRef.current = () => startCall(true);

  // è‡ªå‹•é–‹å§‹é€šè©±
  useEffect(() => {
    if (isReady && !isConnected && !isConnecting) {
      console.log('[VideoCall] Auto-starting call...');
      startCall(true);
    }
  }, [isReady]); // eslint-disable-line react-hooks/exhaustive-deps

  // çµæŸé€šè©± - ä½¿ç”¨ useCallback ç¢ºä¿ç©©å®šçš„å¼•ç”¨
  const endCall = useCallback(async () => {
    const client = clientRef.current;
    console.log('[VideoCall] Ending call...');

    try {
      // åœæ­¢ä¸¦é—œé–‰æœ¬åœ°éŸ³è¨Šè»Œé“ - ä½¿ç”¨ ref ç¢ºä¿å–å¾—æœ€æ–°çš„ track
      const audioTrack = localAudioTrackRef.current;
      if (audioTrack) {
        console.log('[VideoCall] Stopping audio track');
        try {
          audioTrack.stop();
          audioTrack.close();
        } catch (e) {
          console.warn('[VideoCall] Error stopping audio track:', e);
        }
      }

      // åœæ­¢ä¸¦é—œé–‰æœ¬åœ°è¦–è¨Šè»Œé“ - ä½¿ç”¨ ref ç¢ºä¿å–å¾—æœ€æ–°çš„ track
      const videoTrack = localVideoTrackRef.current;
      if (videoTrack) {
        console.log('[VideoCall] Stopping video track');
        try {
          videoTrack.stop();
          videoTrack.close();
        } catch (e) {
          console.warn('[VideoCall] Error stopping video track:', e);
        }
      }

      localAudioTrackRef.current = null;
      localVideoTrackRef.current = null;
      setLocalAudioTrack(null);
      setLocalVideoTrack(null);
      setRemoteVideoTrack(null);
      setRemoteAudioTrack(null);

      // é›¢é–‹é »é“
      if (client && client.connectionState !== 'DISCONNECTED') {
        console.log('[VideoCall] Leaving channel...');
        await client.leave();
      }

      setIsConnected(false);
      setStatus('');
      console.log('[VideoCall] Call ended successfully');
      onClose?.();
    } catch (err) {
      console.error('[VideoCall] Error ending call:', err);
      onClose?.();
    }
  }, [onClose]);

  // åˆ‡æ›éœéŸ³
  const toggleMute = () => {
    if (localAudioTrack) {
      localAudioTrack.setEnabled(isMuted);
      setIsMuted(!isMuted);
    }
  };

  // åˆ‡æ›è¦–è¨Š
  const toggleVideo = () => {
    if (localVideoTrack) {
      localVideoTrack.setEnabled(isVideoOff);
      setIsVideoOff(!isVideoOff);
    }
  };

  // === èªéŸ³ç¿»è­¯åŠŸèƒ½ ===

  // æ’­æ”¾ç¿»è­¯å¾Œçš„èªéŸ³
  const playTranslatedAudio = useCallback(async (base64Audio) => {
    console.log('[DEBUG] playTranslatedAudio è¢«å‘¼å«');
    console.log('[DEBUG] base64Audio é•·åº¦:', base64Audio?.length);
    try {
      if (!audioContextRef.current) {
        console.log('[DEBUG] å»ºç«‹æ–°çš„ AudioContext');
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      }

      console.log('[DEBUG] è§£ç¢¼ base64...');
      const audioData = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
      console.log('[DEBUG] audioData é•·åº¦:', audioData.length);

      console.log('[DEBUG] decodeAudioData...');
      const audioBuffer = await audioContextRef.current.decodeAudioData(audioData.buffer);
      console.log('[DEBUG] audioBuffer æ™‚é•·:', audioBuffer.duration, 'ç§’');

      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      source.start(0);
      console.log('[DEBUG] éŸ³è¨Šæ’­æ”¾é–‹å§‹!');
    } catch (err) {
      console.error('[DEBUG] æ’­æ”¾ç¿»è­¯èªéŸ³å¤±æ•—:', err);
    }
  }, []);

  // é–‹å§‹èªéŸ³ç¿»è­¯
  const startTranslation = useCallback(async () => {
    if (isTranslating) return;

    const token = localStorage.getItem('token');
    const direction = user?.role === 'taiwan' ? 'zh-to-vi' : 'vi-to-zh';

    console.log('========== [DEBUG] é–‹å§‹èªéŸ³ç¿»è­¯ ==========');
    console.log('[DEBUG] user:', user);
    console.log('[DEBUG] user.id:', user?.id);
    console.log('[DEBUG] user.role:', user?.role);
    console.log('[DEBUG] direction:', direction);
    console.log('[DEBUG] matchId:', matchId);
    console.log('[DEBUG] API_URL:', API_URL);
    console.log('[DEBUG] WS_URL:', WS_URL);

    // 1. é€£æ¥ Socket.IO ä¾†æ¥æ”¶å°æ–¹çš„ç¿»è­¯
    console.log('[DEBUG] æ­¥é©Ÿ1: é€£æ¥ Socket.IO...');
    socketRef.current = io(API_URL);

    socketRef.current.on('connect', () => {
      console.log('[DEBUG] Socket.IO é€£ç·šæˆåŠŸ! socket.id:', socketRef.current.id);
      // åŠ å…¥ match room ä»¥æ¥æ”¶å°æ–¹çš„ç¿»è­¯
      console.log('[DEBUG] ç™¼é€ chat:join, matchId:', matchId);
      socketRef.current.emit('chat:join', matchId);
    });

    socketRef.current.on('connect_error', (err) => {
      console.error('[DEBUG] Socket.IO é€£ç·šéŒ¯èª¤:', err);
    });

    // æ¥æ”¶å°æ–¹çš„ç¿»è­¯ï¼ˆæ’­æ”¾èªéŸ³ + é¡¯ç¤ºå­—å¹•ï¼‰
    socketRef.current.on('voice:translation', (data) => {
      console.log('========== [DEBUG] æ”¶åˆ° voice:translation ==========');
      console.log('[DEBUG] data:', data);
      console.log('[DEBUG] data.from:', data.from);
      console.log('[DEBUG] user.id:', user?.id);
      console.log('[DEBUG] data.from === user.id?', data.from === user?.id);

      // å¿½ç•¥è‡ªå·±ç™¼å‡ºçš„ç¿»è­¯
      if (data.from === user?.id) {
        console.log('[DEBUG] é€™æ˜¯è‡ªå·±ç™¼çš„ç¿»è­¯ï¼Œå¿½ç•¥');
        return;
      }

      console.log('[DEBUG] é€™æ˜¯å°æ–¹çš„ç¿»è­¯ï¼Œæº–å‚™é¡¯ç¤ºå­—å¹•å’Œæ’­æ”¾éŸ³è¨Š');
      console.log('[DEBUG] originalText:', data.originalText);
      console.log('[DEBUG] translatedText:', data.translatedText);
      console.log('[DEBUG] audio é•·åº¦:', data.audio?.length);

      // é¡¯ç¤ºå°æ–¹èªªçš„è©±ï¼ˆç¿»è­¯å¾Œçš„ç‰ˆæœ¬ï¼‰
      setPartnerSubtitle(data.translatedText);
      setLatency(data.latency || 0);

      // æ’­æ”¾ç¿»è­¯å¾Œçš„èªéŸ³ï¼ˆé€™æ˜¯å°æ–¹èªªçš„è©±ï¼Œç¿»è­¯æˆæˆ‘çš„èªè¨€ï¼‰
      if (data.audio) {
        console.log('[DEBUG] æ’­æ”¾ç¿»è­¯èªéŸ³...');
        playTranslatedAudio(data.audio);
      }

      // 5 ç§’å¾Œæ¸…é™¤å­—å¹•
      setTimeout(() => {
        setPartnerSubtitle('');
      }, 5000);
    });

    // 2. é€£æ¥èªéŸ³ç¿»è­¯ WebSocketï¼ˆç™¼é€è‡ªå·±çš„èªéŸ³ï¼‰
    const wsUrl = `${WS_URL}/ws/voice?token=${token}&direction=${direction}&matchId=${matchId}`;
    console.log('[DEBUG] æ­¥é©Ÿ2: é€£æ¥ Voice WebSocket...');
    console.log('[DEBUG] wsUrl:', wsUrl);
    voiceWsRef.current = new WebSocket(wsUrl);

    voiceWsRef.current.onopen = () => {
      console.log('[DEBUG] Voice WebSocket é€£ç·šæˆåŠŸ!');
      setStatus('ç¿»è­¯å·²é–‹å•Ÿ');
    };

    voiceWsRef.current.onmessage = (event) => {
      console.log('[DEBUG] Voice WebSocket æ”¶åˆ°è¨Šæ¯:', event.data);
      try {
        const data = JSON.parse(event.data);
        console.log('[DEBUG] è§£æå¾Œçš„è³‡æ–™:', data);
        console.log('[DEBUG] data.type:', data.type);

        // åªè™•ç†è‡ªå·±èªªçš„è©±ï¼ˆé¡¯ç¤ºå­—å¹•ï¼Œä¸æ’­æ”¾éŸ³è¨Šï¼‰
        if (data.type === 'my-speech') {
          console.log('[DEBUG] ===== æ”¶åˆ° my-speech =====');
          console.log('[DEBUG] originalText:', data.originalText);
          console.log('[DEBUG] æº–å‚™å‘¼å« setMySubtitle...');

          // é¡¯ç¤ºæˆ‘èªªçš„è©±
          setMySubtitle(data.originalText);
          console.log('[DEBUG] setMySubtitle å·²å‘¼å«ï¼Œå€¼:', data.originalText);

          setLatency(data.latency?.total || 0);

          // 5 ç§’å¾Œæ¸…é™¤å­—å¹•
          setTimeout(() => {
            console.log('[DEBUG] 5ç§’åˆ°ï¼Œæ¸…é™¤ mySubtitle');
            setMySubtitle('');
          }, 5000);
        } else if (data.type === 'connected') {
          console.log('[DEBUG] Voice WS é€£ç·šç¢ºèª:', data.message);
        } else if (data.type === 'error') {
          console.error('[DEBUG] ç¿»è­¯éŒ¯èª¤:', data.message);
        } else {
          console.log('[DEBUG] æœªçŸ¥çš„è¨Šæ¯é¡å‹:', data.type);
        }
      } catch (err) {
        console.error('[DEBUG] è§£æ WebSocket è¨Šæ¯å¤±æ•—:', err);
      }
    };

    voiceWsRef.current.onerror = (err) => {
      console.error('[DEBUG] Voice WebSocket éŒ¯èª¤:', err);
    };

    voiceWsRef.current.onclose = (event) => {
      console.log('[DEBUG] Voice WebSocket é—œé–‰, code:', event.code, 'reason:', event.reason);
    };

    // 3. é–‹å§‹éŒ„éŸ³
    console.log('[DEBUG] æ­¥é©Ÿ3: é–‹å§‹éŒ„éŸ³...');
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('[DEBUG] å–å¾—éº¥å…‹é¢¨æˆåŠŸ');

      // è¨ºæ–·ï¼šæª¢æŸ¥ç€è¦½å™¨æ”¯æ´çš„ mimeType
      console.log('[DEBUG] ===== MediaRecorder mimeType è¨ºæ–· =====');
      console.log('[DEBUG] audio/webm;codecs=opus æ”¯æ´:', MediaRecorder.isTypeSupported('audio/webm;codecs=opus'));
      console.log('[DEBUG] audio/webm æ”¯æ´:', MediaRecorder.isTypeSupported('audio/webm'));
      console.log('[DEBUG] audio/ogg;codecs=opus æ”¯æ´:', MediaRecorder.isTypeSupported('audio/ogg;codecs=opus'));
      console.log('[DEBUG] audio/mp4 æ”¯æ´:', MediaRecorder.isTypeSupported('audio/mp4'));
      console.log('[DEBUG] audio/wav æ”¯æ´:', MediaRecorder.isTypeSupported('audio/wav'));

      // é¸æ“‡æ”¯æ´çš„ mimeType
      let selectedMimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(selectedMimeType)) {
        if (MediaRecorder.isTypeSupported('audio/webm')) {
          selectedMimeType = 'audio/webm';
        } else if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
          selectedMimeType = 'audio/ogg;codecs=opus';
        } else {
          selectedMimeType = ''; // ä½¿ç”¨ç€è¦½å™¨é è¨­
        }
      }
      console.log('[DEBUG] é¸æ“‡çš„ mimeType:', selectedMimeType);

      const recorderOptions = selectedMimeType ? { mimeType: selectedMimeType } : {};
      mediaRecorderRef.current = new MediaRecorder(stream, recorderOptions);
      console.log('[DEBUG] å¯¦éš›ä½¿ç”¨çš„ mimeType:', mediaRecorderRef.current.mimeType);

      let chunkCount = 0;
      mediaRecorderRef.current.ondataavailable = (event) => {
        chunkCount++;
        console.log(`[DEBUG] éŒ„éŸ³ç‰‡æ®µ #${chunkCount}, å¤§å°: ${event.data.size} bytes`);
        if (event.data.size > 0 && voiceWsRef.current?.readyState === WebSocket.OPEN) {
          console.log('[DEBUG] ç™¼é€éŸ³è¨Šåˆ° WebSocket...');
          voiceWsRef.current.send(event.data);
        } else {
          console.log('[DEBUG] ç„¡æ³•ç™¼é€: size=', event.data.size, 'wsState=', voiceWsRef.current?.readyState);
        }
      };

      // æ¯ 2 ç§’å‚³ä¸€æ¬¡éŸ³è¨Šç‰‡æ®µ
      mediaRecorderRef.current.start(2000);
      setIsTranslating(true);
      console.log('[DEBUG] éŒ„éŸ³é–‹å§‹ï¼Œæ¯ 2 ç§’ç™¼é€ä¸€æ¬¡');
    } catch (err) {
      console.error('[DEBUG] éŒ„éŸ³å•Ÿå‹•å¤±æ•—:', err);
      setError('ç„¡æ³•å•Ÿç”¨éº¥å…‹é¢¨éŒ„éŸ³');
    }
  }, [isTranslating, user?.role, user?.id, matchId, playTranslatedAudio]);

  // åœæ­¢èªéŸ³ç¿»è­¯
  const stopTranslation = useCallback(() => {
    console.log('[VideoCall] Stopping translation');

    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      mediaRecorderRef.current = null;
    }

    if (voiceWsRef.current) {
      voiceWsRef.current.close();
      voiceWsRef.current = null;
    }

    // é—œé–‰ Socket.IO é€£æ¥
    if (socketRef.current) {
      socketRef.current.disconnect();
      socketRef.current = null;
    }

    setIsTranslating(false);
    setMySubtitle('');
    setPartnerSubtitle('');
    setStatus('');
  }, []);

  // å…ƒä»¶å¸è¼‰æ™‚æ¸…ç† - ä½¿ç”¨ refs ç¢ºä¿æ­£ç¢ºæ¸…ç†
  useEffect(() => {
    return () => {
      console.log('[VideoCall] Component unmounting, cleaning up...');

      // æ¸…ç†èªéŸ³ç¿»è­¯
      if (mediaRecorderRef.current) {
        mediaRecorderRef.current.stop();
        mediaRecorderRef.current.stream?.getTracks().forEach(track => track.stop());
      }
      if (voiceWsRef.current) {
        voiceWsRef.current.close();
      }
      if (socketRef.current) {
        socketRef.current.disconnect();
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }

      // ä½¿ç”¨ refs è€Œé state ä¾†ç¢ºä¿å–å¾—æœ€æ–°çš„ track
      const audioTrack = localAudioTrackRef.current;
      if (audioTrack) {
        console.log('[VideoCall] Cleanup: stopping audio track');
        try {
          audioTrack.stop();
          audioTrack.close();
        } catch (e) {
          console.warn('[VideoCall] Cleanup: error stopping audio:', e);
        }
      }

      const videoTrack = localVideoTrackRef.current;
      if (videoTrack) {
        console.log('[VideoCall] Cleanup: stopping video track');
        try {
          videoTrack.stop();
          videoTrack.close();
        } catch (e) {
          console.warn('[VideoCall] Cleanup: error stopping video:', e);
        }
      }

      const client = clientRef.current;
      if (client && client.connectionState !== 'DISCONNECTED') {
        client.leave().catch((e) => {
          console.warn('[VideoCall] Error leaving on unmount:', e);
        });
      }
    };
  }, []); // ç©ºä¾è³´é™£åˆ—ï¼Œåªåœ¨ unmount æ™‚åŸ·è¡Œ

  return (
    <div className="video-call-overlay">
      <div className="video-call-container">
        {/* é ç«¯è¦–è¨Šï¼ˆå¤§ç•«é¢ï¼‰ */}
        <div className="remote-video-container">
          <div ref={remoteVideoRef} className="remote-video">
            {!remoteVideoTrack && (
              <div className="video-placeholder">
                <span className="placeholder-text">
                  {isConnecting ? 'é€£æ¥ä¸­...' : isConnected ? `ç­‰å¾… ${partnerName} çš„ç•«é¢...` : 'æº–å‚™ä¸­...'}
                </span>
              </div>
            )}
          </div>
          {remoteVideoTrack && <div className="partner-name">{partnerName}</div>}
        </div>

        {/* æœ¬åœ°è¦–è¨Šï¼ˆå°ç•«é¢ï¼‰ */}
        <div className="local-video-container">
          <div ref={localVideoRef} className="local-video">
            {!localVideoTrack && (
              <div className="video-placeholder small">
                <span>æˆ‘</span>
              </div>
            )}
          </div>
        </div>

        {/* å­—å¹•å€åŸŸ - æ”¾åœ¨æœ€å¤–å±¤ç¢ºä¿é¡¯ç¤º */}
        {partnerSubtitle && (
          <div className="subtitle partner-subtitle" style={{ zIndex: 999 }}>
            <span className="subtitle-label">{partnerName}:</span> {partnerSubtitle}
          </div>
        )}
        {mySubtitle && (
          <div className="subtitle my-subtitle" style={{ zIndex: 999 }}>
            <span className="subtitle-label">æˆ‘:</span> {mySubtitle}
          </div>
        )}

        {/* ç¿»è­¯å»¶é²æŒ‡ç¤ºå™¨ */}
        {isTranslating && latency > 0 && (
          <div className="latency-indicator">
            AI ç¿»è­¯å»¶é²: {(latency / 1000).toFixed(1)}s
          </div>
        )}

        {/* DEBUG: æ¸¬è©¦å­—å¹•æŒ‰éˆ• */}
        <button
          onClick={() => {
            console.log('[DEBUG] æ¸¬è©¦å­—å¹•æŒ‰éˆ•è¢«é»æ“Š');
            setMySubtitle('æ¸¬è©¦ï¼šæˆ‘èªªçš„è©±');
            setPartnerSubtitle('Test: Partner speech');
            setTimeout(() => {
              setMySubtitle('');
              setPartnerSubtitle('');
            }, 3000);
          }}
          style={{
            position: 'absolute',
            top: '10px',
            right: '10px',
            zIndex: 9999,
            padding: '10px',
            background: 'red',
            color: 'white',
            border: 'none',
            borderRadius: '5px',
            cursor: 'pointer',
          }}
        >
          æ¸¬è©¦å­—å¹•
        </button>

        {/* DEBUG: é¡¯ç¤ºç•¶å‰å­—å¹•ç‹€æ…‹ */}
        <div style={{
          position: 'absolute',
          top: '50px',
          right: '10px',
          zIndex: 9999,
          padding: '10px',
          background: 'rgba(0,0,0,0.8)',
          color: 'lime',
          fontSize: '12px',
          maxWidth: '200px',
        }}>
          mySubtitle: "{mySubtitle}"<br/>
          partnerSubtitle: "{partnerSubtitle}"
        </div>

        {/* ç‹€æ…‹è¨Šæ¯ */}
        {status && (
          <div className="status-message">
            {status}
          </div>
        )}

        {/* éŒ¯èª¤è¨Šæ¯ */}
        {error && (
          <div className="error-message">
            {error}
          </div>
        )}

        {/* æ§åˆ¶æŒ‰éˆ• */}
        <div className="video-controls">
          {/* ç¿»è­¯é–‹é—œæŒ‰éˆ• */}
          <button
            onClick={isTranslating ? stopTranslation : startTranslation}
            className={`control-btn ${isTranslating ? 'active translate-on' : ''}`}
            title={isTranslating ? 'é—œé–‰ç¿»è­¯' : 'é–‹å•Ÿç¿»è­¯'}
            disabled={!isConnected}
          >
            {isTranslating ? 'ğŸŒ' : 'ğŸ—£ï¸'}
          </button>

          {/* éœéŸ³æŒ‰éˆ• */}
          <button
            onClick={toggleMute}
            className={`control-btn ${isMuted ? 'active' : ''}`}
            title={isMuted ? 'å–æ¶ˆéœéŸ³' : 'éœéŸ³'}
            disabled={!localAudioTrack}
          >
            {isMuted ? 'ğŸ”‡' : 'ğŸ¤'}
          </button>

          {/* è¦–è¨Šé–‹é—œæŒ‰éˆ• */}
          <button
            onClick={toggleVideo}
            className={`control-btn ${isVideoOff ? 'active' : ''}`}
            title={isVideoOff ? 'é–‹å•Ÿè¦–è¨Š' : 'é—œé–‰è¦–è¨Š'}
            disabled={!localVideoTrack}
          >
            {isVideoOff ? 'ğŸ“·' : 'ğŸ¥'}
          </button>

          {/* çµæŸé€šè©±æŒ‰éˆ• */}
          <button
            onClick={endCall}
            className="control-btn end-btn"
            title="çµæŸé€šè©±"
          >
            ğŸ“
          </button>
        </div>
      </div>
    </div>
  );
}

// src/pages/Diagnostic.jsx
// æ¸¬è©¦è¨ºæ–·é é¢ - ç¬¬å››éšæ®µï¼šè‡ªå‹•æ ¡æº–æµç¨‹

import { useState, useEffect, useRef, useCallback } from 'react';
import { useNavigate } from 'react-router-dom';
import './Diagnostic.css';

// API åŸºç¤ URL
const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:3000';

// localStorage key for calibration data
const CALIBRATION_KEY = 'voiceCalibration';

export default function Diagnostic() {
  const navigate = useNavigate();

  // è£ç½®åˆ—è¡¨
  const [cameras, setCameras] = useState([]);
  const [microphones, setMicrophones] = useState([]);
  const [speakers, setSpeakers] = useState([]);

  // é¸æ“‡çš„è£ç½®
  const [selectedCamera, setSelectedCamera] = useState('');
  const [selectedMicrophone, setSelectedMicrophone] = useState('');
  const [selectedSpeaker, setSelectedSpeaker] = useState('');

  // ç‹€æ…‹
  const [cameraStream, setCameraStream] = useState(null);
  const [micVolume, setMicVolume] = useState(0);
  const [peakVolume, setPeakVolume] = useState(0);
  const [isTestingAudio, setIsTestingAudio] = useState(false);
  const [error, setError] = useState('');

  // ç¿»è­¯æ¸¬è©¦ç‹€æ…‹
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [direction, setDirection] = useState('zh-to-vi');
  const [translationResult, setTranslationResult] = useState(null);
  const [translationHistory, setTranslationHistory] = useState([]);

  // TTS ç‹€æ…‹
  const [playingTtsId, setPlayingTtsId] = useState(null); // æ­£åœ¨æ’­æ”¾çš„é …ç›® ID
  const [ttsError, setTtsError] = useState('');

  // æ ¡æº–ç‹€æ…‹ï¼ˆæ–°ç‰ˆç°¡åŒ–è¨­è¨ˆï¼‰
  const [calibrationStep, setCalibrationStep] = useState(0); // 0=å¾…æ©Ÿ, 1=éœéŸ³æ¡æ¨£ä¸­, 2=èªªè©±æ¡æ¨£ä¸­
  const [calibrationProgress, setCalibrationProgress] = useState(0); // 0-100
  const [calibrationMessage, setCalibrationMessage] = useState('');

  // å››å€‹å¯æ‰‹å‹•èª¿æ•´çš„æ ¡æº–å€¼
  const [silenceAvg, setSilenceAvg] = useState(5);     // éœéŸ³å¹³å‡å€¼
  const [speechMax, setSpeechMax] = useState(40);      // èªªè©±æœ€å¤§å€¼
  const [threshold, setThreshold] = useState(22);       // åˆ¤æ–·é–€æª»
  const [sentenceEndWait, setSentenceEndWait] = useState(500); // å¥å°¾ç­‰å¾…æ™‚é–“ (ms)

  // å³æ™‚èªªè©±ç‹€æ…‹ï¼ˆä½¿ç”¨æ»‘å‹•å»¶ä¼¸é‚è¼¯ï¼‰
  const [isSpeakingNow, setIsSpeakingNow] = useState(false);
  const speakingEndTimeRef = useRef(0); // èªªè©±ç‹€æ…‹çµæŸæ™‚é–“ï¼ˆæ»‘å‹•å»¶ä¼¸ç”¨ï¼‰

  // æ›²ç·šåœ–ç‹€æ…‹
  const [isChartPaused, setIsChartPaused] = useState(false); // æ›²ç·šåœ–æ˜¯å¦æš«åœ
  const [hoverInfo, setHoverInfo] = useState(null); // æ»‘é¼ æ‡¸åœè³‡è¨Š { x, time, volume }

  // Refs
  const videoRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const micStreamRef = useRef(null);
  const animationFrameRef = useRef(null);
  const waveformCanvasRef = useRef(null);
  const spectrumCanvasRef = useRef(null);
  const peakVolumeTimeoutRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const calibrationSamplesRef = useRef([]); // æ ¡æº–æ™‚æ”¶é›†çš„éŸ³é‡æ¨£æœ¬
  const calibrationIntervalRef = useRef(null);
  const currentVolumeRef = useRef(0); // å³æ™‚éŸ³é‡ ref
  const volumeHistoryRef = useRef([]); // éŸ³é‡æ­·å²ï¼ˆæœ€è¿‘ 10 ç§’ï¼‰
  const calibrationChartRef = useRef(null); // æ ¡æº–æ›²ç·šåœ– canvas
  const calibrationChartAnimationRef = useRef(null); // æ ¡æº–æ›²ç·šåœ–å‹•ç•«

  // è¼‰å…¥å·²å„²å­˜çš„æ ¡æº–è³‡æ–™
  useEffect(() => {
    const saved = localStorage.getItem(CALIBRATION_KEY);
    if (saved) {
      try {
        const data = JSON.parse(saved);
        setSilenceAvg(data.silenceAvg || 5);
        setSpeechMax(data.speechMax || 40);
        setThreshold(data.threshold || 22);
        setSentenceEndWait(data.sentenceEndWait || 500);
        console.log('[æ ¡æº–] è¼‰å…¥å·²å„²å­˜çš„æ ¡æº–è³‡æ–™:', data);
      } catch (e) {
        console.error('[æ ¡æº–] ç„¡æ³•è§£æå·²å„²å­˜çš„æ ¡æº–è³‡æ–™');
      }
    }
  }, []);

  // è‡ªå‹•æ›´æ–°åˆ¤æ–·é–€æª»ï¼ˆç•¶éœéŸ³å¹³å‡å€¼æˆ–èªªè©±æœ€å¤§å€¼æ”¹è®Šæ™‚ï¼‰
  const updateThresholdAuto = useCallback(() => {
    const newThreshold = Math.round((silenceAvg + speechMax) / 2);
    setThreshold(newThreshold);
  }, [silenceAvg, speechMax]);

  // åˆ—å‡ºæ‰€æœ‰è£ç½®
  const enumerateDevices = useCallback(async () => {
    try {
      // å…ˆè«‹æ±‚æ¬Šé™æ‰èƒ½å–å¾—å®Œæ•´è£ç½®åç¨±
      await navigator.mediaDevices.getUserMedia({ audio: true, video: true });

      const devices = await navigator.mediaDevices.enumerateDevices();

      const videoInputs = devices.filter(d => d.kind === 'videoinput');
      const audioInputs = devices.filter(d => d.kind === 'audioinput');
      const audioOutputs = devices.filter(d => d.kind === 'audiooutput');

      setCameras(videoInputs);
      setMicrophones(audioInputs);
      setSpeakers(audioOutputs);

      // è¨­å®šé è¨­è£ç½®
      if (videoInputs.length > 0 && !selectedCamera) {
        setSelectedCamera(videoInputs[0].deviceId);
      }
      if (audioInputs.length > 0 && !selectedMicrophone) {
        setSelectedMicrophone(audioInputs[0].deviceId);
      }
      if (audioOutputs.length > 0 && !selectedSpeaker) {
        setSelectedSpeaker(audioOutputs[0].deviceId);
      }
    } catch (err) {
      console.error('ç„¡æ³•åˆ—å‡ºè£ç½®:', err);
      setError('ç„¡æ³•å–å¾—è£ç½®æ¬Šé™: ' + err.message);
    }
  }, [selectedCamera, selectedMicrophone, selectedSpeaker]);

  // åˆå§‹åŒ–
  useEffect(() => {
    enumerateDevices();

    return () => {
      // æ¸…ç†
      if (cameraStream) {
        cameraStream.getTracks().forEach(track => track.stop());
      }
      if (micStreamRef.current) {
        micStreamRef.current.getTracks().forEach(track => track.stop());
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, []);

  // æ”å½±æ©Ÿé è¦½
  useEffect(() => {
    if (!selectedCamera) return;

    const startCamera = async () => {
      try {
        // åœæ­¢èˆŠçš„ä¸²æµ
        if (cameraStream) {
          cameraStream.getTracks().forEach(track => track.stop());
        }

        const stream = await navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: selectedCamera } }
        });

        setCameraStream(stream);
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      } catch (err) {
        console.error('æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—:', err);
        setError('æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—: ' + err.message);
      }
    };

    startCamera();
  }, [selectedCamera]);

  // éº¥å…‹é¢¨éŸ³é‡ç›£æ¸¬
  useEffect(() => {
    if (!selectedMicrophone) return;

    const startMicMonitor = async () => {
      try {
        // åœæ­¢èˆŠçš„ä¸²æµ
        if (micStreamRef.current) {
          micStreamRef.current.getTracks().forEach(track => track.stop());
        }
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }

        const stream = await navigator.mediaDevices.getUserMedia({
          audio: { deviceId: { exact: selectedMicrophone } }
        });
        micStreamRef.current = stream;

        // å»ºç«‹ AudioContext
        if (!audioContextRef.current) {
          audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
        }

        const audioContext = audioContextRef.current;
        const analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        analyserRef.current = analyser;

        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);

        // é–‹å§‹ç›£æ¸¬éŸ³é‡èˆ‡ç¹ªè£½è¦–è¦ºåŒ–
        const frequencyData = new Uint8Array(analyser.frequencyBinCount);
        const timeDomainData = new Uint8Array(analyser.fftSize);

        const updateVisualization = () => {
          // å–å¾—é »åŸŸè³‡æ–™ï¼ˆç”¨æ–¼é »è­œåœ–å’ŒéŸ³é‡ï¼‰
          analyser.getByteFrequencyData(frequencyData);
          // å–å¾—æ™‚åŸŸè³‡æ–™ï¼ˆç”¨æ–¼æ³¢å½¢åœ–ï¼‰
          analyser.getByteTimeDomainData(timeDomainData);

          // è¨ˆç®—éŸ³é‡
          const average = frequencyData.reduce((a, b) => a + b, 0) / frequencyData.length;
          setMicVolume(average);
          currentVolumeRef.current = average; // åŒæ­¥æ›´æ–° refï¼ˆä¾›æ ¡æº–ä½¿ç”¨ï¼‰

          // æ›´æ–°å³°å€¼éŸ³é‡ï¼ˆä¿æŒ 1 ç§’ï¼‰
          if (average > peakVolume) {
            setPeakVolume(average);
            if (peakVolumeTimeoutRef.current) {
              clearTimeout(peakVolumeTimeoutRef.current);
            }
            peakVolumeTimeoutRef.current = setTimeout(() => {
              setPeakVolume(0);
            }, 1000);
          }

          // ç¹ªè£½æ³¢å½¢åœ–
          drawWaveform(timeDomainData);
          // ç¹ªè£½é »è­œåœ–
          drawSpectrum(frequencyData);

          animationFrameRef.current = requestAnimationFrame(updateVisualization);
        };

        updateVisualization();
      } catch (err) {
        console.error('éº¥å…‹é¢¨å•Ÿå‹•å¤±æ•—:', err);
        setError('éº¥å…‹é¢¨å•Ÿå‹•å¤±æ•—: ' + err.message);
      }
    };

    startMicMonitor();
  }, [selectedMicrophone]);

  // ç¹ªè£½æ³¢å½¢åœ–ï¼ˆæ™‚åŸŸï¼‰
  const drawWaveform = (dataArray) => {
    const canvas = waveformCanvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;

    // æ¸…é™¤ç•«å¸ƒ
    ctx.fillStyle = 'rgba(0, 0, 0, 0.3)';
    ctx.fillRect(0, 0, width, height);

    // ç¹ªè£½æ³¢å½¢
    ctx.lineWidth = 2;
    ctx.strokeStyle = '#4CAF50';
    ctx.beginPath();

    const sliceWidth = width / dataArray.length;
    let x = 0;

    for (let i = 0; i < dataArray.length; i++) {
      const v = dataArray[i] / 128.0; // è½‰æ›ç‚º 0-2 ç¯„åœ
      const y = (v * height) / 2;

      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }

      x += sliceWidth;
    }

    ctx.lineTo(width, height / 2);
    ctx.stroke();

    // ç¹ªè£½ä¸­ç·š
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.2)';
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.stroke();
  };

  // ç¹ªè£½é »è­œåœ–ï¼ˆé »åŸŸ FFTï¼‰
  const drawSpectrum = (dataArray) => {
    const canvas = spectrumCanvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;

    // æ¸…é™¤ç•«å¸ƒ
    ctx.fillStyle = 'rgba(0, 0, 0, 0.3)';
    ctx.fillRect(0, 0, width, height);

    // ç¹ªè£½é »è­œæ¢
    const barCount = dataArray.length;
    const barWidth = width / barCount;
    const barGap = 1;

    for (let i = 0; i < barCount; i++) {
      const value = dataArray[i];
      const barHeight = (value / 255) * height;

      // æ¼¸å±¤é¡è‰²ï¼šä½é »ç¶ è‰² -> ä¸­é »é»ƒè‰² -> é«˜é »ç´…è‰²
      const hue = 120 - (i / barCount) * 120; // 120=ç¶ , 60=é»ƒ, 0=ç´…
      const saturation = 80;
      const lightness = 50;

      ctx.fillStyle = `hsl(${hue}, ${saturation}%, ${lightness}%)`;
      ctx.fillRect(
        i * barWidth + barGap / 2,
        height - barHeight,
        barWidth - barGap,
        barHeight
      );
    }

    // ç¹ªè£½é »ç‡æ¨™ç±¤
    ctx.fillStyle = 'rgba(255, 255, 255, 0.5)';
    ctx.font = '10px monospace';
    ctx.fillText('ä½é »', 5, height - 5);
    ctx.fillText('é«˜é »', width - 30, height - 5);
  };

  // æ’­æ”¾æ¸¬è©¦éŸ³
  const playTestSound = async () => {
    setIsTestingAudio(true);
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();

      // å‰µå»ºç°¡å–®çš„æ¸¬è©¦éŸ³ï¼ˆä¸‰å€‹éŸ³ç¬¦ï¼‰
      const playNote = (frequency, startTime, duration) => {
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();

        oscillator.type = 'sine';
        oscillator.frequency.setValueAtTime(frequency, startTime);

        gainNode.gain.setValueAtTime(0.3, startTime);
        gainNode.gain.exponentialRampToValueAtTime(0.01, startTime + duration);

        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);

        oscillator.start(startTime);
        oscillator.stop(startTime + duration);
      };

      // æ’­æ”¾ä¸‰å€‹éŸ³ç¬¦ (Do-Mi-Sol)
      const now = audioContext.currentTime;
      playNote(523.25, now, 0.3);        // C5
      playNote(659.25, now + 0.3, 0.3);  // E5
      playNote(783.99, now + 0.6, 0.5);  // G5

      // è¨­å®šè¼¸å‡ºè£ç½®ï¼ˆå¦‚æœæ”¯æ´ï¼‰
      if (selectedSpeaker && audioContext.setSinkId) {
        await audioContext.setSinkId(selectedSpeaker);
      }

      setTimeout(() => {
        setIsTestingAudio(false);
        audioContext.close();
      }, 1200);
    } catch (err) {
      console.error('æ’­æ”¾æ¸¬è©¦éŸ³å¤±æ•—:', err);
      setError('æ’­æ”¾æ¸¬è©¦éŸ³å¤±æ•—: ' + err.message);
      setIsTestingAudio(false);
    }
  };

  // éŸ³é‡æ¢é¡è‰²
  const getVolumeColor = (volume) => {
    if (volume < 30) return '#4CAF50';  // ç¶ è‰²
    if (volume < 60) return '#FFC107';  // é»ƒè‰²
    return '#F44336';  // ç´…è‰²
  };

  // é–‹å§‹éŒ„éŸ³ï¼ˆæŒ‰ä¸‹æŒ‰éˆ•ï¼‰
  const startRecording = async () => {
    if (!micStreamRef.current) {
      setError('éº¥å…‹é¢¨æœªå•Ÿå‹•');
      return;
    }

    try {
      audioChunksRef.current = [];
      const recorder = new MediaRecorder(micStreamRef.current, {
        mimeType: 'audio/webm;codecs=opus',
      });

      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      recorder.onstop = async () => {
        await processRecording();
      };

      mediaRecorderRef.current = recorder;
      recorder.start();
      setIsRecording(true);
      setTranslationResult(null);
    } catch (err) {
      console.error('éŒ„éŸ³å•Ÿå‹•å¤±æ•—:', err);
      setError('éŒ„éŸ³å•Ÿå‹•å¤±æ•—: ' + err.message);
    }
  };

  // åœæ­¢éŒ„éŸ³ï¼ˆæ”¾é–‹æŒ‰éˆ•ï¼‰
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
    }
  };

  // è™•ç†éŒ„éŸ³ä¸¦é€å‡ºç¿»è­¯
  const processRecording = async () => {
    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });

      // æª¢æŸ¥éŸ³è¨Šå¤§å°
      if (audioBlob.size < 1000) {
        setTranslationResult({
          success: false,
          error: 'éŒ„éŸ³å¤ªçŸ­ï¼Œè«‹èªªä¹…ä¸€é»',
        });
        setIsProcessing(false);
        return;
      }

      // è½‰æ›ç‚º base64
      const reader = new FileReader();
      reader.readAsDataURL(audioBlob);

      reader.onloadend = async () => {
        const base64Audio = reader.result.split(',')[1];

        try {
          const response = await fetch(`${API_BASE}/api/diagnostic/translate`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              audio: base64Audio,
              direction,
            }),
          });

          const result = await response.json();

          setTranslationResult(result);

          // åŠ å…¥æ­·å²è¨˜éŒ„
          if (result.success) {
            setTranslationHistory(prev => [
              {
                ...result,
                timestamp: new Date().toISOString(),
              },
              ...prev.slice(0, 9), // åªä¿ç•™æœ€è¿‘ 10 ç­†
            ]);
          }
        } catch (err) {
          console.error('ç¿»è­¯ API éŒ¯èª¤:', err);
          setTranslationResult({
            success: false,
            error: 'ç„¡æ³•é€£æ¥ä¼ºæœå™¨: ' + err.message,
          });
        }

        setIsProcessing(false);
      };
    } catch (err) {
      console.error('è™•ç†éŒ„éŸ³éŒ¯èª¤:', err);
      setTranslationResult({
        success: false,
        error: 'è™•ç†éŒ„éŸ³å¤±æ•—: ' + err.message,
      });
      setIsProcessing(false);
    }
  };

  // åˆ‡æ›ç¿»è­¯æ–¹å‘
  const toggleDirection = () => {
    setDirection(prev => prev === 'zh-to-vi' ? 'vi-to-zh' : 'zh-to-vi');
  };

  // æ¸…é™¤æ­·å²
  const clearHistory = () => {
    setTranslationHistory([]);
    setTranslationResult(null);
  };

  // æ’­æ”¾ TTS èªéŸ³
  const playTts = async (text, targetLang, itemId = 'current') => {
    if (playingTtsId) return; // å·²ç¶“åœ¨æ’­æ”¾ä¸­

    setPlayingTtsId(itemId);
    setTtsError('');

    try {
      const response = await fetch(`${API_BASE}/api/diagnostic/tts`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text,
          language: targetLang,
        }),
      });

      const result = await response.json();

      if (!result.success) {
        throw new Error(result.error || 'TTS å¤±æ•—');
      }

      // æ’­æ”¾éŸ³è¨Š
      const audioData = `data:audio/mp3;base64,${result.audio}`;
      const audio = new Audio(audioData);

      // è¨­å®šè¼¸å‡ºè£ç½®ï¼ˆå¦‚æœæ”¯æ´ï¼‰
      if (selectedSpeaker && audio.setSinkId) {
        try {
          await audio.setSinkId(selectedSpeaker);
        } catch (e) {
          console.warn('ç„¡æ³•è¨­å®šè¼¸å‡ºè£ç½®:', e);
        }
      }

      audio.onended = () => {
        setPlayingTtsId(null);
      };

      audio.onerror = (e) => {
        console.error('éŸ³è¨Šæ’­æ”¾éŒ¯èª¤:', e);
        setTtsError('éŸ³è¨Šæ’­æ”¾å¤±æ•—');
        setPlayingTtsId(null);
      };

      await audio.play();

    } catch (err) {
      console.error('TTS éŒ¯èª¤:', err);
      setTtsError(err.message || 'TTS å¤±æ•—');
      setPlayingTtsId(null);
    }
  };

  // å–å¾—ç¿»è­¯å¾Œçš„ç›®æ¨™èªè¨€
  const getTargetLang = (dir) => {
    return dir === 'zh-to-vi' ? 'vi' : 'zh';
  };

  // ========== æ ¡æº–åŠŸèƒ½ï¼ˆæ–°ç‰ˆç°¡åŒ–è¨­è¨ˆï¼‰==========

  // ä¿å­˜æ›²ç·šåœ–ç‹€æ…‹
  const chartStateRef = useRef({
    padding: { top: 20, right: 80, bottom: 30, left: 50 },
    maxVolume: 100,
    tenSecondsAgo: Date.now() - 10000,
  });

  // ç¹ªè£½æ ¡æº–æ›²ç·šåœ–ï¼ˆæŒçºŒåŸ·è¡Œï¼‰
  const drawCalibrationChart = useCallback(() => {
    const canvas = calibrationChartRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    const width = canvas.width;
    const height = canvas.height;
    const padding = chartStateRef.current.padding;
    const chartWidth = width - padding.left - padding.right;
    const chartHeight = height - padding.top - padding.bottom;

    // å–å¾—å³æ™‚éŸ³é‡
    const volume = currentVolumeRef.current;
    const now = Date.now();
    const exceedsThreshold = volume > threshold;

    // æ»‘å‹•å»¶ä¼¸é‚è¼¯ï¼šåˆ¤æ–·èªªè©±ç‹€æ…‹
    let speaking = false;
    if (exceedsThreshold) {
      // éŸ³é‡è¶…éé–€æª» â†’ å»¶ä¼¸èªªè©±ç‹€æ…‹åˆ°ã€Œç¾åœ¨ + å¥å°¾ç­‰å¾…æ™‚é–“ã€
      speakingEndTimeRef.current = now + sentenceEndWait;
      speaking = true;
    } else if (now < speakingEndTimeRef.current) {
      // é‚„åœ¨å¥å°¾ç­‰å¾…æ™‚é–“å…§ â†’ ç¶­æŒèªªè©±ç‹€æ…‹
      speaking = true;
    } else {
      // è¶…éå¥å°¾ç­‰å¾…æ™‚é–“ä¸”éŸ³é‡ä½æ–¼é–€æª» â†’ èªªè©±çµæŸ
      speaking = false;
    }

    // åªåœ¨éæš«åœæ™‚åŠ å…¥æ­·å²å’Œæ›´æ–°
    if (!isChartPaused) {
      volumeHistoryRef.current.push({ time: now, volume, speaking });
      // åªä¿ç•™æœ€è¿‘ 10 ç§’
      const tenSecondsAgo = now - 10000;
      volumeHistoryRef.current = volumeHistoryRef.current.filter(d => d.time > tenSecondsAgo);
      chartStateRef.current.tenSecondsAgo = tenSecondsAgo;
    }

    // æ›´æ–°èªªè©±ç‹€æ…‹
    setIsSpeakingNow(speaking);

    // æ¸…é™¤ç•«å¸ƒ
    ctx.fillStyle = 'rgba(0, 0, 0, 0.9)';
    ctx.fillRect(0, 0, width, height);

    // è¨ˆç®— Y è»¸ç¯„åœï¼ˆå‹•æ…‹è‡ªå‹•ç¸®æ”¾ï¼‰
    // å–ä»¥ä¸‹ä¸‰å€‹å€¼ä¸­çš„æœ€å¤§å€¼ Ã— 1.3ï¼š
    // 1. ç›®å‰ç•«é¢ä¸­æ›²ç·šçš„æœ€å¤§éŸ³é‡
    // 2. èªªè©±æœ€å¤§å€¼æ¬„ä½çš„æ•¸å€¼
    // 3. åˆ¤æ–·é–€æª»æ¬„ä½çš„æ•¸å€¼ Ã— 2
    const chartMaxVolume = volumeHistoryRef.current.length > 0
      ? Math.max(...volumeHistoryRef.current.map(d => d.volume))
      : 0;
    const maxVolume = Math.max(chartMaxVolume, speechMax, threshold * 2) * 1.3;
    chartStateRef.current.maxVolume = maxVolume;

    // ç¹ªè£½ Y è»¸åˆ»åº¦
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.15)';
    ctx.fillStyle = 'rgba(255, 255, 255, 0.6)';
    ctx.font = '11px monospace';
    ctx.textAlign = 'right';
    ctx.lineWidth = 1;

    const yTicks = 5;
    for (let i = 0; i <= yTicks; i++) {
      const value = Math.round((maxVolume / yTicks) * i);
      const y = padding.top + chartHeight - (i / yTicks) * chartHeight;

      ctx.beginPath();
      ctx.moveTo(padding.left, y);
      ctx.lineTo(padding.left + chartWidth, y);
      ctx.stroke();

      ctx.fillText(value.toString(), padding.left - 8, y + 4);
    }

    // ç¹ªè£½ X è»¸æ¨™ç±¤
    ctx.textAlign = 'center';
    ctx.fillText('10ç§’å‰', padding.left + 30, height - 8);
    ctx.fillText('ç¾åœ¨', padding.left + chartWidth - 20, height - 8);

    // ç¹ªè£½ä¸‰æ¢æ°´å¹³ç·š
    const drawHorizontalLine = (value, color, label, dashed = false) => {
      if (value <= 0 || value > maxVolume) return;
      const y = padding.top + chartHeight - (value / maxVolume) * chartHeight;

      ctx.strokeStyle = color;
      ctx.lineWidth = 2;
      if (dashed) ctx.setLineDash([5, 5]);
      ctx.beginPath();
      ctx.moveTo(padding.left, y);
      ctx.lineTo(padding.left + chartWidth, y);
      ctx.stroke();
      ctx.setLineDash([]);

      // æ¨™ç±¤
      ctx.fillStyle = color;
      ctx.textAlign = 'left';
      ctx.font = '10px monospace';
      ctx.fillText(`${label}: ${value}`, padding.left + chartWidth + 5, y + 4);
    };

    // è—ç·š = éœéŸ³å¹³å‡å€¼
    drawHorizontalLine(silenceAvg, '#2196F3', 'éœéŸ³', true);
    // ç¶ ç·š = èªªè©±æœ€å¤§å€¼
    drawHorizontalLine(speechMax, '#4CAF50', 'èªªè©±', true);
    // ç´…ç·š = åˆ¤æ–·é–€æª»ï¼ˆæœ€é‡è¦ï¼Œå¯¦ç·šï¼‰
    drawHorizontalLine(threshold, '#F44336', 'é–€æª»', false);

    const tenSecondsAgo = chartStateRef.current.tenSecondsAgo;

    // ç¹ªè£½éŸ³é‡æ›²ç·š
    if (volumeHistoryRef.current.length > 1) {
      ctx.lineWidth = 2;
      ctx.beginPath();

      let lastSpeaking = null;
      volumeHistoryRef.current.forEach((point, index) => {
        const x = padding.left + ((point.time - tenSecondsAgo) / 10000) * chartWidth;
        const y = padding.top + chartHeight - (Math.min(point.volume, maxVolume) / maxVolume) * chartHeight;

        if (lastSpeaking !== point.speaking) {
          if (index > 0) {
            ctx.stroke();
            ctx.beginPath();
            ctx.moveTo(x, y);
          }
          ctx.strokeStyle = point.speaking ? '#4CAF50' : 'rgba(255, 255, 255, 0.5)';
          lastSpeaking = point.speaking;
        }

        if (index === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }
      });
      ctx.stroke();

      // ç›®å‰é»ï¼ˆåªåœ¨éæš«åœæ™‚é¡¯ç¤ºï¼‰
      if (!isChartPaused) {
        const lastPoint = volumeHistoryRef.current[volumeHistoryRef.current.length - 1];
        const lastX = padding.left + chartWidth;
        const lastY = padding.top + chartHeight - (Math.min(lastPoint.volume, maxVolume) / maxVolume) * chartHeight;

        ctx.beginPath();
        ctx.arc(lastX, lastY, 6, 0, Math.PI * 2);
        ctx.fillStyle = lastPoint.speaking ? '#4CAF50' : 'rgba(255, 255, 255, 0.6)';
        ctx.fill();
      }
    }

    // ç¹ªè£½æ»‘é¼ æ‡¸åœè³‡è¨Š
    if (hoverInfo && volumeHistoryRef.current.length > 0) {
      const { x: hoverX } = hoverInfo;

      // ç¹ªè£½å‚ç›´è™›ç·š
      ctx.strokeStyle = 'rgba(255, 255, 255, 0.7)';
      ctx.lineWidth = 1;
      ctx.setLineDash([3, 3]);
      ctx.beginPath();
      ctx.moveTo(hoverX, padding.top);
      ctx.lineTo(hoverX, padding.top + chartHeight);
      ctx.stroke();
      ctx.setLineDash([]);

      // æ‰¾åˆ°æœ€æ¥è¿‘çš„è³‡æ–™é»
      const relativeX = (hoverX - padding.left) / chartWidth;
      const targetTime = tenSecondsAgo + relativeX * 10000;
      let closestPoint = volumeHistoryRef.current[0];
      let minDiff = Math.abs(closestPoint.time - targetTime);

      for (const point of volumeHistoryRef.current) {
        const diff = Math.abs(point.time - targetTime);
        if (diff < minDiff) {
          minDiff = diff;
          closestPoint = point;
        }
      }

      // è¨ˆç®—æ™‚é–“å·®
      const secondsAgo = Math.round((now - closestPoint.time) / 1000 * 10) / 10;

      // ç¹ªè£½è³‡è¨Šæ¡†
      const infoText = `${secondsAgo}ç§’å‰: ${Math.round(closestPoint.volume)}`;
      ctx.font = '12px monospace';
      const textWidth = ctx.measureText(infoText).width + 16;
      const infoX = Math.min(hoverX + 10, width - textWidth - 10);
      const infoY = padding.top + 10;

      ctx.fillStyle = 'rgba(0, 0, 0, 0.85)';
      ctx.fillRect(infoX, infoY, textWidth, 24);
      ctx.strokeStyle = 'rgba(255, 255, 255, 0.5)';
      ctx.strokeRect(infoX, infoY, textWidth, 24);
      ctx.fillStyle = '#fff';
      ctx.textAlign = 'left';
      ctx.fillText(infoText, infoX + 8, infoY + 16);

      // æ¨™è¨˜è©²é»
      const pointY = padding.top + chartHeight - (Math.min(closestPoint.volume, maxVolume) / maxVolume) * chartHeight;
      const pointX = padding.left + ((closestPoint.time - tenSecondsAgo) / 10000) * chartWidth;
      ctx.beginPath();
      ctx.arc(pointX, pointY, 5, 0, Math.PI * 2);
      ctx.fillStyle = '#FFC107';
      ctx.fill();
      ctx.strokeStyle = '#fff';
      ctx.lineWidth = 2;
      ctx.stroke();
    }

    // æš«åœæ™‚é¡¯ç¤ºæš«åœæ¨™è¨˜
    if (isChartPaused) {
      ctx.fillStyle = 'rgba(255, 152, 0, 0.9)';
      ctx.font = 'bold 12px sans-serif';
      ctx.textAlign = 'right';
      ctx.fillText('â¸ å·²æš«åœ', width - 10, 15);
    }

    calibrationChartAnimationRef.current = requestAnimationFrame(drawCalibrationChart);
  }, [silenceAvg, speechMax, threshold, sentenceEndWait, isChartPaused, hoverInfo]);

  // å•Ÿå‹•æ ¡æº–æ›²ç·šåœ–
  useEffect(() => {
    if (calibrationChartRef.current) {
      drawCalibrationChart();
    }
    return () => {
      if (calibrationChartAnimationRef.current) {
        cancelAnimationFrame(calibrationChartAnimationRef.current);
      }
    };
  }, [drawCalibrationChart]);

  // è™•ç†æ»‘é¼ åœ¨æ›²ç·šåœ–ä¸Šç§»å‹•
  const handleChartMouseMove = useCallback((e) => {
    const canvas = calibrationChartRef.current;
    if (!canvas) return;

    const rect = canvas.getBoundingClientRect();
    const scaleX = canvas.width / rect.width;
    const x = (e.clientX - rect.left) * scaleX;
    const padding = chartStateRef.current.padding;

    // åªåœ¨åœ–è¡¨å€åŸŸå…§é¡¯ç¤º
    if (x >= padding.left && x <= canvas.width - padding.right) {
      setHoverInfo({ x });
    } else {
      setHoverInfo(null);
    }
  }, []);

  // æ»‘é¼ é›¢é–‹æ›²ç·šåœ–
  const handleChartMouseLeave = useCallback(() => {
    setHoverInfo(null);
  }, []);

  // åˆ‡æ›æ›²ç·šåœ–æš«åœ/ç¹¼çºŒ
  const toggleChartPause = () => {
    setIsChartPaused(prev => !prev);
  };

  // é–‹å§‹è‡ªå‹•æ ¡æº–
  const startAutoCalibration = () => {
    setCalibrationStep(1);
    setCalibrationProgress(0);
    setCalibrationMessage('è«‹ä¿æŒå®‰éœ 5 ç§’...');
    calibrationSamplesRef.current = [];

    console.log('[æ ¡æº–] é–‹å§‹éœéŸ³æ¡æ¨£...');

    const samples = [];
    let elapsed = 0;
    const duration = 5000;
    const interval = 50;

    calibrationIntervalRef.current = setInterval(() => {
      const volume = currentVolumeRef.current;
      samples.push(volume);
      elapsed += interval;
      setCalibrationProgress(Math.round((elapsed / duration) * 100));

      if (elapsed >= duration) {
        clearInterval(calibrationIntervalRef.current);

        // è¨ˆç®—éœéŸ³å¹³å‡å€¼ï¼ˆèƒŒæ™¯å™ªéŸ³æ˜¯æŒçºŒç©©å®šçš„è²éŸ³ï¼Œç”¨å¹³å‡å€¼æ›´æº–ç¢ºï¼‰
        const avgVal = Math.round(samples.reduce((a, b) => a + b, 0) / samples.length);
        setSilenceAvg(avgVal);
        console.log('[æ ¡æº–] éœéŸ³æ¡æ¨£å®Œæˆ, å¹³å‡å€¼:', avgVal);

        // é€²å…¥èªªè©±æ¡æ¨£ï¼Œä¸¦å‚³å…¥éœéŸ³å¹³å‡å€¼
        startSpeechSampling(avgVal);
      }
    }, interval);
  };

  // èªªè©±æ¡æ¨£
  const startSpeechSampling = (silenceAvgVal) => {
    setCalibrationStep(2);
    setCalibrationProgress(0);
    setCalibrationMessage('è«‹æ­£å¸¸èªªè©± 5 ç§’ï¼ˆä¾‹å¦‚æ•¸ 1 åˆ° 10ï¼‰...');

    console.log('[æ ¡æº–] é–‹å§‹èªªè©±æ¡æ¨£...');

    const samples = [];
    let elapsed = 0;
    const duration = 5000;
    const interval = 50;

    calibrationIntervalRef.current = setInterval(() => {
      const volume = currentVolumeRef.current;
      samples.push(volume);
      elapsed += interval;
      setCalibrationProgress(Math.round((elapsed / duration) * 100));

      if (elapsed >= duration) {
        clearInterval(calibrationIntervalRef.current);

        // è¨ˆç®—èªªè©±æœ€å¤§å€¼ï¼ˆäººè²æ˜¯è„ˆè¡æ³¢ï¼Œç”¨æœ€å¤§å€¼æ‰èƒ½æ•æ‰åˆ°èªªè©±çš„å³°å€¼ï¼‰
        const maxVal = Math.round(Math.max(...samples));
        setSpeechMax(maxVal);

        // è‡ªå‹•è¨ˆç®—é–€æª» = (éœéŸ³å¹³å‡å€¼ + èªªè©±æœ€å¤§å€¼) / 2
        const newThreshold = Math.round((silenceAvgVal + maxVal) / 2);
        setThreshold(newThreshold);

        console.log('[æ ¡æº–] èªªè©±æ¡æ¨£å®Œæˆ, æœ€å¤§å€¼:', maxVal, 'é–€æª»:', newThreshold);

        // å®Œæˆ
        setCalibrationStep(0);
        setCalibrationProgress(0);
        setCalibrationMessage('æ ¡æº–å®Œæˆï¼');

        // è‡ªå‹•å„²å­˜
        saveCalibrationData(silenceAvgVal, maxVal, newThreshold);
      }
    }, interval);
  };

  // å„²å­˜æ ¡æº–è³‡æ–™
  const saveCalibrationData = (silence, speech, thresh) => {
    const data = {
      silenceAvg: silence,
      speechMax: speech,
      threshold: thresh,
      sentenceEndWait: sentenceEndWait,
      calibratedAt: new Date().toISOString(),
    };
    localStorage.setItem(CALIBRATION_KEY, JSON.stringify(data));
    console.log('[æ ¡æº–] å·²å„²å­˜:', data);
  };

  // æ‰‹å‹•å„²å­˜
  const saveCurrentCalibration = () => {
    saveCalibrationData(silenceAvg, speechMax, threshold);
    setCalibrationMessage('å·²å„²å­˜ï¼');
    setTimeout(() => setCalibrationMessage(''), 2000);
  };

  // å–æ¶ˆæ ¡æº–
  const cancelCalibration = () => {
    if (calibrationIntervalRef.current) {
      clearInterval(calibrationIntervalRef.current);
    }
    setCalibrationStep(0);
    setCalibrationProgress(0);
    setCalibrationMessage('');
  };

  // é‡ç½®ç‚ºé è¨­å€¼
  const resetToDefaults = () => {
    setSilenceAvg(5);
    setSpeechMax(40);
    setThreshold(22);
    setSentenceEndWait(500);
    localStorage.removeItem(CALIBRATION_KEY);
    setCalibrationMessage('å·²é‡ç½®ç‚ºé è¨­å€¼');
    setTimeout(() => setCalibrationMessage(''), 2000);
  };

  return (
    <div className="diagnostic-page">
      <header className="diagnostic-header">
        <button className="back-btn" onClick={() => navigate(-1)}>
          â† è¿”å›
        </button>
        <h1>è£ç½®è¨ºæ–·</h1>
      </header>

      {error && (
        <div className="error-banner">
          {error}
          <button onClick={() => setError('')}>Ã—</button>
        </div>
      )}

      <div className="diagnostic-content">
        {/* æ”å½±æ©Ÿå€å¡Š */}
        <section className="device-section">
          <h2>æ”å½±æ©Ÿ</h2>
          <select
            value={selectedCamera}
            onChange={(e) => setSelectedCamera(e.target.value)}
            className="device-select"
          >
            {cameras.map(camera => (
              <option key={camera.deviceId} value={camera.deviceId}>
                {camera.label || `æ”å½±æ©Ÿ ${cameras.indexOf(camera) + 1}`}
              </option>
            ))}
          </select>
          <div className="camera-preview">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
            />
            {!cameraStream && (
              <div className="camera-placeholder">
                æ”å½±æ©Ÿè¼‰å…¥ä¸­...
              </div>
            )}
          </div>
        </section>

        {/* éº¥å…‹é¢¨å€å¡Š */}
        <section className="device-section">
          <h2>éº¥å…‹é¢¨</h2>
          <select
            value={selectedMicrophone}
            onChange={(e) => setSelectedMicrophone(e.target.value)}
            className="device-select"
          >
            {microphones.map(mic => (
              <option key={mic.deviceId} value={mic.deviceId}>
                {mic.label || `éº¥å…‹é¢¨ ${microphones.indexOf(mic) + 1}`}
              </option>
            ))}
          </select>
          <div className="volume-meter">
            <div className="volume-label">éŸ³é‡</div>
            <div className="volume-bar-container">
              <div
                className="volume-bar"
                style={{
                  width: `${Math.min(micVolume, 100)}%`,
                  backgroundColor: getVolumeColor(micVolume),
                }}
              />
            </div>
            <div className="volume-value">{Math.round(micVolume)}</div>
          </div>
          <p className="hint">å°è‘—éº¥å…‹é¢¨èªªè©±ï¼ŒéŸ³é‡æ¢æ‡‰è©²æœƒè·³å‹•</p>
        </section>

        {/* éŸ³è¨Šè¦–è¦ºåŒ–å€å¡Š */}
        <section className="device-section visualization-section">
          <h2>éŸ³è¨Šè¦–è¦ºåŒ–</h2>

          {/* éŸ³é‡æ•¸å€¼é¡¯ç¤º */}
          <div className="volume-stats">
            <div className="stat-item">
              <span className="stat-label">ç›®å‰éŸ³é‡</span>
              <span className="stat-value">{Math.round(micVolume)}</span>
            </div>
            <div className="stat-item">
              <span className="stat-label">å³°å€¼</span>
              <span className="stat-value peak">{Math.round(peakVolume)}</span>
            </div>
            <div className="stat-item">
              <span className="stat-label">ç‹€æ…‹</span>
              <span className={`stat-value status ${micVolume > 30 ? 'speaking' : 'silent'}`}>
                {micVolume > 30 ? 'èªªè©±ä¸­' : 'éœéŸ³'}
              </span>
            </div>
          </div>

          {/* æ³¢å½¢åœ– */}
          <div className="canvas-container">
            <div className="canvas-label">æ³¢å½¢åœ–ï¼ˆæ™‚åŸŸï¼‰</div>
            <canvas
              ref={waveformCanvasRef}
              width={600}
              height={100}
              className="audio-canvas"
            />
          </div>

          {/* é »è­œåœ– */}
          <div className="canvas-container">
            <div className="canvas-label">é »è­œåœ–ï¼ˆFFT é »åŸŸï¼‰</div>
            <canvas
              ref={spectrumCanvasRef}
              width={600}
              height={120}
              className="audio-canvas"
            />
          </div>

          <p className="hint">èªªè©±æ™‚æ³¢å½¢åœ–å’Œé »è­œåœ–æ‡‰è©²æœ‰æ˜é¡¯è®ŠåŒ–</p>
        </section>

        {/* æ ¡æº–å€å¡Šï¼ˆæ–°ç‰ˆç°¡åŒ–è¨­è¨ˆï¼‰ */}
        <section className="device-section calibration-section-v2">
          <h2>èªéŸ³æ ¡æº–</h2>

          {/* å³æ™‚éŸ³é‡å¤§æ•¸å­—é¡¯ç¤º */}
          <div className="realtime-volume-display">
            <div className="volume-number">{Math.round(micVolume)}</div>
            <div className="volume-label-big">å³æ™‚éŸ³é‡</div>
          </div>

          {/* å››å€‹å¯èª¿æ•´çš„åƒæ•¸è¼¸å…¥ */}
          <div className="calibration-inputs">
            <div className="input-group">
              <label>éœéŸ³å¹³å‡å€¼</label>
              <input
                type="number"
                value={silenceAvg}
                onChange={(e) => setSilenceAvg(Math.max(0, parseInt(e.target.value) || 0))}
                min="0"
                max="100"
              />
              <div className="input-color-indicator silence"></div>
            </div>
            <div className="input-group">
              <label>èªªè©±æœ€å¤§å€¼</label>
              <input
                type="number"
                value={speechMax}
                onChange={(e) => setSpeechMax(Math.max(0, parseInt(e.target.value) || 0))}
                min="0"
                max="200"
              />
              <div className="input-color-indicator speech"></div>
            </div>
            <div className="input-group">
              <label>åˆ¤æ–·é–€æª»</label>
              <input
                type="number"
                value={threshold}
                onChange={(e) => setThreshold(Math.max(0, parseInt(e.target.value) || 0))}
                min="0"
                max="150"
              />
              <div className="input-color-indicator threshold"></div>
            </div>
            <div className="input-group sentence-wait">
              <label>å¥å°¾ç­‰å¾…æ™‚é–“</label>
              <div className="input-with-unit">
                <input
                  type="number"
                  value={sentenceEndWait}
                  onChange={(e) => setSentenceEndWait(Math.max(100, parseInt(e.target.value) || 500))}
                  min="100"
                  max="3000"
                  step="100"
                />
                <span className="input-unit">ms</span>
              </div>
              <div className="input-hint">èªªè©±åœæ­¢å¾Œï¼Œç­‰å¾…é€™æ®µæ™‚é–“æ‰åˆ¤å®šç‚ºå¥å­çµæŸ</div>
            </div>
          </div>

          {/* è‡ªå‹•æ ¡æº–æŒ‰éˆ• */}
          <div className="auto-calibration-area">
            {calibrationStep === 0 ? (
              <button className="calibration-btn primary large" onClick={startAutoCalibration}>
                è‡ªå‹•æ ¡æº–ï¼ˆéœéŸ³5ç§’ â†’ èªªè©±5ç§’ï¼‰
              </button>
            ) : (
              <div className="calibration-in-progress">
                <div className="calibration-step-indicator">
                  {calibrationStep === 1 ? 'æ­¥é©Ÿ 1/2: éœéŸ³æ¡æ¨£ä¸­...' : 'æ­¥é©Ÿ 2/2: èªªè©±æ¡æ¨£ä¸­...'}
                </div>
                <div className="calibration-message">{calibrationMessage}</div>
                <div className="calibration-progress-bar">
                  <div className="progress-fill" style={{ width: `${calibrationProgress}%` }} />
                </div>
                <button className="calibration-btn secondary" onClick={cancelCalibration}>
                  å–æ¶ˆ
                </button>
              </div>
            )}
          </div>

          {/* å³æ™‚éŸ³é‡æ›²ç·šåœ–ï¼ˆæŒçºŒé¡¯ç¤ºï¼‰ */}
          <div className="calibration-chart-container">
            <div className="chart-header">
              <span className="chart-title">å³æ™‚éŸ³é‡æ›²ç·šï¼ˆæœ€è¿‘ 10 ç§’ï¼‰</span>
              <div className="chart-controls">
                <button
                  className={`chart-pause-btn ${isChartPaused ? 'paused' : ''}`}
                  onClick={toggleChartPause}
                >
                  {isChartPaused ? 'â–¶ ç¹¼çºŒé‹ä½œ' : 'â¸ åœæ­¢ç§»å‹•'}
                </button>
                <div className={`speaking-indicator ${isSpeakingNow ? 'speaking' : 'silent'}`}>
                  {isSpeakingNow ? 'â— èªªè©±ä¸­' : 'â—‹ éœéŸ³'}
                </div>
              </div>
            </div>
            <canvas
              ref={calibrationChartRef}
              width={700}
              height={200}
              className="calibration-chart"
              onMouseMove={handleChartMouseMove}
              onMouseLeave={handleChartMouseLeave}
            />
            <div className="chart-legend">
              <span className="legend-item">
                <span className="legend-line silence"></span>éœéŸ³å¹³å‡å€¼ï¼ˆè—ï¼‰
              </span>
              <span className="legend-item">
                <span className="legend-line speech"></span>èªªè©±æœ€å¤§å€¼ï¼ˆç¶ ï¼‰
              </span>
              <span className="legend-item">
                <span className="legend-line threshold"></span>åˆ¤æ–·é–€æª»ï¼ˆç´…ï¼‰
              </span>
            </div>
          </div>

          {/* æ ¡æº–è¨Šæ¯èˆ‡æ“ä½œ */}
          {calibrationMessage && calibrationStep === 0 && (
            <div className="calibration-status-message">{calibrationMessage}</div>
          )}

          <div className="calibration-actions-row">
            <button className="calibration-btn secondary small" onClick={saveCurrentCalibration}>
              å„²å­˜è¨­å®š
            </button>
            <button className="calibration-btn secondary small" onClick={resetToDefaults}>
              é‡ç½®é è¨­
            </button>
          </div>
        </section>

        {/* ç¿»è­¯æ¸¬è©¦å€å¡Š */}
        <section className="device-section translation-section">
          <h2>ç¿»è­¯æ¸¬è©¦</h2>

          {/* èªè¨€æ–¹å‘é¸æ“‡ */}
          <div className="direction-selector">
            <button
              className={`direction-btn ${direction === 'zh-to-vi' ? 'active' : ''}`}
              onClick={() => setDirection('zh-to-vi')}
            >
              ä¸­æ–‡ â†’ è¶Šå—æ–‡
            </button>
            <button
              className={`direction-btn ${direction === 'vi-to-zh' ? 'active' : ''}`}
              onClick={() => setDirection('vi-to-zh')}
            >
              è¶Šå—æ–‡ â†’ ä¸­æ–‡
            </button>
          </div>

          {/* æŒ‰ä½èªªè©±æŒ‰éˆ• */}
          <button
            className={`push-to-talk-btn ${isRecording ? 'recording' : ''} ${isProcessing ? 'processing' : ''}`}
            onMouseDown={startRecording}
            onMouseUp={stopRecording}
            onMouseLeave={stopRecording}
            onTouchStart={startRecording}
            onTouchEnd={stopRecording}
            disabled={isProcessing}
          >
            {isProcessing ? (
              <>è™•ç†ä¸­...</>
            ) : isRecording ? (
              <>éŒ„éŸ³ä¸­... æ”¾é–‹é€å‡º</>
            ) : (
              <>æŒ‰ä½èªªè©±</>
            )}
          </button>

          <p className="hint">
            {direction === 'zh-to-vi'
              ? 'æŒ‰ä½æŒ‰éˆ•èªªä¸­æ–‡ï¼Œæ”¾é–‹å¾Œæœƒç¿»è­¯æˆè¶Šå—æ–‡'
              : 'æŒ‰ä½æŒ‰éˆ•èªªè¶Šå—æ–‡ï¼Œæ”¾é–‹å¾Œæœƒç¿»è­¯æˆä¸­æ–‡'}
          </p>

          {/* TTS éŒ¯èª¤è¨Šæ¯ */}
          {ttsError && (
            <div className="tts-error">
              {ttsError}
              <button onClick={() => setTtsError('')}>Ã—</button>
            </div>
          )}

          {/* ç¿»è­¯çµæœé¡¯ç¤º */}
          {translationResult && (
            <div className={`translation-result ${translationResult.success ? 'success' : 'error'}`}>
              {translationResult.success ? (
                <>
                  <div className="result-row">
                    <span className="result-label">åŸæ–‡ï¼š</span>
                    <span className="result-text original">{translationResult.originalText}</span>
                  </div>
                  <div className="result-row">
                    <span className="result-label">ç¿»è­¯ï¼š</span>
                    <span className="result-text translated">{translationResult.translatedText}</span>
                    <button
                      className={`tts-btn ${playingTtsId === 'current' ? 'playing' : ''}`}
                      onClick={() => playTts(
                        translationResult.translatedText,
                        getTargetLang(translationResult.direction),
                        'current'
                      )}
                      disabled={!!playingTtsId}
                      title="æ’­æ”¾ç¿»è­¯èªéŸ³"
                    >
                      {playingTtsId === 'current' ? '...' : 'ğŸ”Š'}
                    </button>
                  </div>
                  <div className="latency-stats">
                    <div className="latency-item">
                      <span className="latency-label">STT</span>
                      <span className="latency-value">{translationResult.timings?.stt || 0} ms</span>
                    </div>
                    <div className="latency-item">
                      <span className="latency-label">ç¿»è­¯</span>
                      <span className="latency-value">{translationResult.timings?.translate || 0} ms</span>
                    </div>
                    <div className="latency-item total">
                      <span className="latency-label">ç¸½è¨ˆ</span>
                      <span className="latency-value">{translationResult.timings?.total || 0} ms</span>
                    </div>
                  </div>
                </>
              ) : (
                <div className="error-message">{translationResult.error}</div>
              )}
            </div>
          )}

          {/* ç¿»è­¯æ­·å² */}
          {translationHistory.length > 0 && (
            <div className="translation-history">
              <div className="history-header">
                <h3>æ­·å²è¨˜éŒ„</h3>
                <button className="clear-history-btn" onClick={clearHistory}>æ¸…é™¤</button>
              </div>
              <div className="history-list">
                {translationHistory.map((item, index) => (
                  <div key={index} className="history-item">
                    <div className="history-texts">
                      <span className="history-original">{item.originalText}</span>
                      <span className="history-arrow">â†’</span>
                      <span className="history-translated">{item.translatedText}</span>
                    </div>
                    <div className="history-actions">
                      <button
                        className={`tts-btn small ${playingTtsId === `history-${index}` ? 'playing' : ''}`}
                        onClick={() => playTts(
                          item.translatedText,
                          getTargetLang(item.direction),
                          `history-${index}`
                        )}
                        disabled={!!playingTtsId}
                        title="æ’­æ”¾ç¿»è­¯èªéŸ³"
                      >
                        {playingTtsId === `history-${index}` ? '...' : 'ğŸ”Š'}
                      </button>
                      <span className="history-latency">{item.timings?.total || 0}ms</span>
                    </div>
                  </div>
                ))}
              </div>
            </div>
          )}
        </section>

        {/* å–‡å­å€å¡Š */}
        <section className="device-section">
          <h2>å–‡å­</h2>
          <select
            value={selectedSpeaker}
            onChange={(e) => setSelectedSpeaker(e.target.value)}
            className="device-select"
          >
            {speakers.length > 0 ? (
              speakers.map(speaker => (
                <option key={speaker.deviceId} value={speaker.deviceId}>
                  {speaker.label || `å–‡å­ ${speakers.indexOf(speaker) + 1}`}
                </option>
              ))
            ) : (
              <option value="">ä½¿ç”¨ç³»çµ±é è¨­</option>
            )}
          </select>
          <button
            className={`test-sound-btn ${isTestingAudio ? 'playing' : ''}`}
            onClick={playTestSound}
            disabled={isTestingAudio}
          >
            {isTestingAudio ? 'æ’­æ”¾ä¸­...' : 'æ’­æ”¾æ¸¬è©¦éŸ³'}
          </button>
          <p className="hint">é»æ“ŠæŒ‰éˆ•æ‡‰è©²æœƒè½åˆ°ä¸‰å€‹éŸ³ç¬¦</p>
        </section>

        {/* è£ç½®ç‹€æ…‹æ‘˜è¦ */}
        <section className="status-summary">
          <h2>è£ç½®ç‹€æ…‹</h2>
          <div className="status-grid">
            <div className={`status-item ${cameraStream ? 'ok' : 'error'}`}>
              <span className="status-icon">{cameraStream ? 'âœ“' : 'âœ—'}</span>
              <span>æ”å½±æ©Ÿ</span>
            </div>
            <div className={`status-item ${micVolume > 0 ? 'ok' : 'warning'}`}>
              <span className="status-icon">{micVolume > 0 ? 'âœ“' : '?'}</span>
              <span>éº¥å…‹é¢¨</span>
            </div>
            <div className="status-item ok">
              <span className="status-icon">âœ“</span>
              <span>å–‡å­</span>
            </div>
          </div>
        </section>
      </div>
    </div>
  );
}

// src/pipeline/generate-test-audio.js
// ä½¿ç”¨ OpenAI TTS ç”¢ç”Ÿæ¸¬è©¦éŸ³æª”
import 'dotenv/config';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const TEST_TEXTS = {
  chinese: 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä¾†è‡ªå°ç£çš„ç”·ç”Ÿï¼Œæˆ‘å¾ˆå–œæ­¡è¶Šå—æ–‡åŒ–ï¼Œå¸Œæœ›å¯ä»¥èªè­˜ä½ ',
  vietnamese: 'Xin chÃ o, tÃ´i ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n. TÃ´i muá»‘n há»c tiáº¿ng Trung.',
};

async function generateTestAudio() {
  console.log('ğŸ™ï¸ é–‹å§‹ç”¢ç”Ÿæ¸¬è©¦éŸ³æª”...\n');

  // ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
  const testAudioDir = 'test-audio';
  if (!fs.existsSync(testAudioDir)) {
    fs.mkdirSync(testAudioDir, { recursive: true });
  }

  // ç”¢ç”Ÿä¸­æ–‡æ¸¬è©¦éŸ³æª”
  console.log('ç”¢ç”Ÿä¸­æ–‡æ¸¬è©¦éŸ³æª”...');
  console.log(`  æ–‡å­—: "${TEST_TEXTS.chinese}"`);

  const chineseResponse = await openai.audio.speech.create({
    model: 'tts-1',
    voice: 'onyx',  // ç”·è²
    input: TEST_TEXTS.chinese,
  });

  const chinesePath = path.join(testAudioDir, 'chinese_test.mp3');
  const chineseBuffer = Buffer.from(await chineseResponse.arrayBuffer());
  fs.writeFileSync(chinesePath, chineseBuffer);
  console.log(`  âœ… å·²å„²å­˜: ${chinesePath}\n`);

  // ç”¢ç”Ÿè¶Šå—æ–‡æ¸¬è©¦éŸ³æª”
  console.log('ç”¢ç”Ÿè¶Šå—æ–‡æ¸¬è©¦éŸ³æª”...');
  console.log(`  æ–‡å­—: "${TEST_TEXTS.vietnamese}"`);

  const vietnameseResponse = await openai.audio.speech.create({
    model: 'tts-1',
    voice: 'nova',  // å¥³è²
    input: TEST_TEXTS.vietnamese,
  });

  const vietnamesePath = path.join(testAudioDir, 'vietnamese_test.mp3');
  const vietnameseBuffer = Buffer.from(await vietnameseResponse.arrayBuffer());
  fs.writeFileSync(vietnamesePath, vietnameseBuffer);
  console.log(`  âœ… å·²å„²å­˜: ${vietnamesePath}\n`);

  console.log('ğŸ‰ æ¸¬è©¦éŸ³æª”ç”¢ç”Ÿå®Œæˆï¼');
  console.log('\nç¾åœ¨å¯ä»¥åŸ·è¡Œ npm test ä¾†æ¸¬è©¦ Pipeline');
}

generateTestAudio().catch(console.error);
